# Podcast Pipeline — 完整方案

## 项目概述

端到端播客克隆管线：从数据采集到 AI 播客生成。

**目标播客**：《独树不成林》（鬼鬼祟祟的树 / 仲树）
**Apple Podcast ID**: `1711052890`
**RSS Feed**: `https://feed.xyzfm.space/y9qnpfdrctnx`（289 集，含全部历史数据）

---

## 架构总览

```
┌─────────────────────────────────────────────────────────────┐
│                     DATA PIPELINE                           │
│                                                             │
│  RSS Feed ──→ 过滤 ──→ 下载 ──→ 转录 ──→ LLM校对 ──→ HF   │
│  (289集)    (去对谈/   (音频)   (Whisper)  (术语修正)  存储  │
│              付费)                                           │
└──────────────────────────┬──────────────────────────────────┘
                           │
              ┌────────────┼────────────────┐
              ▼            ▼                ▼
┌──────────────────┐ ┌──────────────┐ ┌──────────────────┐
│   音频数据准备    │ │  知识库构建   │ │   风格档案       │
│                  │ │              │ │                  │
│ • 音频切片       │ │ • 实体提取   │ │ • 话题偏好       │
│ • 质量分析       │ │   (哲学家/   │ │ • 论述结构       │
│ • 参考音频筛选   │ │    书名/概念)│ │ • 语言特征       │
│                  │ │ • 网络搜索   │ │ • 口头禅         │
│ → 参考音频池     │ │   补充资料   │ │ • 段落节奏       │
│   (Top 50 干净)  │ │ • 向量化存储 │ │                  │
└──────────────────┘ │              │ └──────────────────┘
                     │ → RAG 检索库 │
                     └──────┬───────┘
                            │
              ┌─────────────┼─────────────┐
              ▼             ▼             ▼
┌──────────────────────────────────────────────────────────────┐
│                    GENERATION PIPELINE                        │
│                                                              │
│  主题 ──→ RAG检索 ──→ LLM生成脚本 ──→ 分句 ──→ IndexTTS-2   │
│           知识库       (风格约束)              (zero-shot)    │
│                                                ──→ 拼接 MP3  │
└──────────────────────────────────────────────────────────────┘
```

---

## 支线一：Data Pipeline

### 1.1 数据获取

**增量数据（每日）**：
- GitHub Action `check-new-episodes.yml` 每天 10:00 SGT 自动检查 RSS
- 发现新集 → 下载 → 转录 → 提 PR → CodeRabbit 审查 → 自动合并

**存量数据（一次性回填）**：
- RSS feed 包含 289 集完整历史
- 通过 `backfill.yml` workflow 分批下载（每次 10-20 集，避免超时）
- 断点续传：已下载的集数自动跳过

**RSS Feed 信息**：
```
URL: https://feed.xyzfm.space/y9qnpfdrctnx
来源: Apple Podcast (通过 iTunes Lookup API 获取)
总集数: 289 (ep0 ~ ep306，含跳号)
最新: 306-词典有什么用？
最早: 0-播客介绍
音频格式: M4A/MP3
```

### 1.2 过滤规则

自动过滤以下类型：
- **对谈类**：标题含"对话"/"对谈"/"嘉宾"/"访谈"（双人声纹污染单口模型）
- **付费内容**：音频时长 < 1 分钟（试听版）
- **非正式内容**：ep0（播客介绍）、特别节目

过滤在转录之前执行，节省 GPU 成本。

**模块**: `src/ingest/filter.py`（已有，需扩展过滤规则）

### 1.3 转录

- **工具**: Modal + Whisper large-v3
- **GPU**: A10G
- **语言**: zh (中文)
- **输出**: JSON (含 segments 时间戳) + Markdown
- **已有**: `src/transcribe/modal_whisper.py`

### 1.4 LLM 校对

Whisper 对中文专有名词错误率高，需要 LLM 校对：
- 哲学家人名（海德格尔、阿伦特、萨特、尼采...）
- 书名（《存在与时间》《人的境况》《查拉图斯特拉如是说》...）
- 学术术语（存在主义、现象学、本体论...）
- 校对时带知识库做 grounding，提高准确率
- 输出校对后的文本 + diff 标注修改处

**模块**: `src/proofread/` 🆕

### 1.5 数据准备

**音频切片**：
- webrtcvad + 能量/频谱过滤
- 切片长度 3-15 秒
- 输出 WAV (24kHz/16bit/mono)

**质量分析**（已验证）：
- SNR（信噪比）
- 频谱平坦度
- 零交叉率
- 综合质量评分排序

**参考音频筛选**：
- 从全部切片中选 Top 50（按质量评分）
- 覆盖多个 episode 确保风格多样性
- 用于 IndexTTS-2 zero-shot 推理

**模块**: `src/slice/` 🆕

### 1.6 风格档案

从校对后的转录文本中分析并建立主播风格档案：

- **话题选择偏好**：国际政治 ~35%、哲学思想 ~25%、个人叙事 ~25%、社会批判 ~15%
- **论述结构**：个人故事引入 → 背景铺垫 → 哲学家/理论引用 → 核心论点 → 个人反思
- **语言特征**：口语化长句、"对吧"/"你知道"/"实际上" 等口头禅
- **段落节奏**：开场 1-2 分钟 → 背景 5-8 分钟 → 核心 15-20 分钟 → 反思 5-8 分钟 → 结尾 1-2 分钟

风格档案用于约束 LLM 生成脚本时的风格一致性。

**模块**: `src/style/` 🆕
**已有产出**: `data/style-guide.md`（基于 15 集分析）

---

## 支线二：知识库构建

### 2.1 实体提取

从校对后的转录文本中提取结构化实体：

| 实体类型 | 示例 | 提取方式 |
|----------|------|----------|
| 哲学家/思想家 | 阿伦特、海德格尔、萨特、尼采 | NER + LLM |
| 书名/著作 | 《人的境况》《存在与时间》 | 正则 + LLM |
| 概念/术语 | 存在主义、本体论、行动理论 | LLM |
| 历史事件 | 工业革命、二战 | LLM |
| 引用关系 | 阿伦特批评茨威格 | LLM |

每个实体建一个条目：名称、简介、相关集数、原文引用上下文。

### 2.2 知识补充

对提取的实体，通过网络搜索补充：
- 人物简介（维基百科）
- 著作摘要
- 核心概念解释
- 相关人物/著作的关联关系

### 2.3 向量化存储（RAG 检索库）

**两层检索架构**：

**第一层：结构化实体库**
- 格式：JSON / SQLite
- 用途：精确匹配（"阿伦特" → 直接命中）
- 字段：name, type, description, episodes[], quotes[]

**第二层：语义检索库**
- 切片：校对后文本按段落切分（500-1000 字/chunk，150 字重叠）
- Embedding：`bge-m3`（中文效果最佳）
- 向量库：FAISS（本地，零成本）
- 检索：同时查两层，实体精确匹配 + 语义相似度

**模块**: `src/knowledge/` 🆕

---

## 支线三：播客生成

### 3.1 脚本生成

```
输入: 主题（如"AI时代人的不可替代性"）
  ↓
RAG 检索: 从知识库找相关内容（哲学家观点、历史案例、原播客引用）
  ↓
LLM 生成: 带风格档案约束的脚本生成
  - system prompt 包含风格指南
  - 检索到的知识作为 context
  - 输出完整播客脚本（3000-5000 字）
  ↓
分句: 按自然停顿切分为 30-50 个语句
  ↓
[可选] 人工审核/微调
```

**模块**: `src/generate/` 🆕

### 3.2 语音合成

- **模型**: IndexTTS-2 (zero-shot, model_dim=1280)
- **运行环境**: Modal (A10G GPU)
- **参考音频**: 从 curated pool (Top 50) 智能轮换
- **配置**: 无情感参数（V8 配置，最自然）
- **输出**: 逐句 WAV → ffmpeg 拼接 → MP3

**参考音频匹配策略**：
- 开场/结尾句 → 使用最高质量参考音频
- 叙述句 → 轮换使用不同参考音频
- 未来优化：根据句子语义匹配风格相近的参考音频

**模块**: `src/synthesize/` 🆕

### 3.3 后期处理

- 句间停顿（0.3s）
- 音量归一化
- 输出 MP3 (VBR ~192kbps)
- [未来] 背景音乐（Suno AI）

---

## 存储方案

### HuggingFace Datasets（推荐）

| Repo | 内容 | 预估大小 | 成本 |
|------|------|----------|------|
| `carlnoah6/podcast-pipeline-transcripts` | 校对后转录文本 | ~50 MB | 免费 |
| `carlnoah6/podcast-pipeline-audio` | 原始音频文件 | ~10 GB | 免费 |
| `carlnoah6/podcast-pipeline-slices` | 音频切片 + 参考音频池 | ~2 GB | 免费 |
| `carlnoah6/podcast-pipeline-knowledge` | 知识库 + 实体库 | ~100 MB | 免费 |

**为什么选 HuggingFace**：
- 公开 repo 完全免费，无存储上限（软限制 300GB/repo）
- 原生支持 Dataset 格式（Parquet），方便后续训练/分析
- Git LFS 管理大文件，支持版本控制
- 社区生态好，方便分享和复用
- 对比 S3（~$0.3/月/15GB）或 GCS，HF 零成本且功能更丰富

**注意**：免费账户 LFS 下载带宽 1GB/月。如果需要频繁下载大文件，考虑 Pro ($9/月) 或自建 mirror。

---

## 项目结构

```
podcast-pipeline/
├── docs/
│   └── PLAN.md              # 本文档
├── src/
│   ├── ingest/              # ✅ 已有 - RSS 获取 + 过滤
│   │   ├── rss.py
│   │   └── filter.py
│   ├── transcribe/          # ✅ 已有 - Modal Whisper
│   │   └── modal_whisper.py
│   ├── postprocess/         # ✅ 已有 - 格式化
│   │   └── formatter.py
│   ├── proofread/           # 🆕 LLM 校对
│   │   └── correct.py
│   ├── slice/               # 🆕 音频切片 + 质量分析
│   │   ├── segment.py       # VAD 切片
│   │   └── analyze.py       # 质量评分 + 筛选
│   ├── knowledge/           # 🆕 知识库构建
│   │   ├── extract.py       # 实体提取
│   │   ├── enrich.py        # 网络搜索补充
│   │   └── index.py         # FAISS 向量化
│   ├── style/               # 🆕 风格档案
│   │   └── analyze.py
│   ├── generate/            # 🆕 RAG + 脚本生成
│   │   ├── rag.py           # 知识库检索
│   │   └── script.py        # LLM 脚本生成
│   ├── synthesize/          # 🆕 TTS 合成
│   │   ├── modal_indextts.py  # IndexTTS-2 推理
│   │   └── assemble.py      # 音频拼接
│   └── publish/             # ✅ 已有 - HF 同步
├── scripts/
│   ├── run_pipeline.py      # ✅ 已有 - 转录管线
│   ├── generate_episode.py  # 🆕 一键生成新集
│   ├── backfill.py          # 🆕 存量数据回填
│   ├── build_knowledge.py   # 🆕 构建知识库
│   ├── sync_hf.py           # ✅ 已有
│   └── create_hf_repo.py    # ✅ 已有
├── .github/workflows/
│   ├── check-new-episodes.yml  # ✅ 已有 - 每日增量
│   ├── backfill.yml            # 🆕 存量回填
│   ├── ci.yml                  # ✅ 已有
│   ├── luna-review.yml         # ✅ 已有
│   └── sync-hf.yml             # ✅ 已有
├── data/
│   ├── transcripts/         # 转录文本
│   ├── knowledge/           # 知识库
│   └── style/               # 风格档案
└── tests/
```

---

## 实施优先级

### Phase 1: 数据回填（1-2 周）
1. 更新 `rss.py` 支持 Apple Podcast RSS feed
2. 实现 `backfill.py` 分批下载 289 集
3. 批量转录（Modal Whisper）
4. 同步到 HuggingFace

### Phase 2: 数据处理（1 周）
1. LLM 校对模块
2. 音频切片 + 质量分析（已有脚本，需整合）
3. 参考音频池构建

### Phase 3: 知识库（1 周）
1. 实体提取
2. 网络搜索补充
3. FAISS 向量化

### Phase 4: 生成管线（1 周）
1. RAG 检索
2. 风格约束脚本生成
3. IndexTTS-2 合成（已有脚本，需整合）
4. `generate_episode.py` 一键脚本

---

## 已验证的技术决策

| 决策 | 选择 | 原因 |
|------|------|------|
| TTS 模型 | IndexTTS-2 (zero-shot) | V8 效果最佳，无需 LoRA 训练 |
| 情感参数 | 关闭 (默认值) | V9 测试显示开启后过于夸张 |
| 参考音频数量 | Top 50 | 平衡音质和风格多样性 |
| 参考音频轮换 | 智能匹配 | 开场/结尾固定，中间轮换 |
| 转录模型 | Whisper large-v3 | 中文效果最好 |
| GPU 平台 | Modal | 按需付费，冷启动快 |
| 存储 | HuggingFace | 免费，Dataset 生态好 |
| 向量库 | FAISS | 本地零成本，数据量不大够用 |
| Embedding | bge-m3 | 中文语义检索效果最佳 |
